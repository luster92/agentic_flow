"""
Semantic Cache â€” ì‹œë§¨í‹± ìºì‹± ë ˆì´ì–´
=====================================
ChromaDB ê¸°ë°˜ ë²¡í„° ìœ ì‚¬ë„ë¥¼ í™œìš©í•œ ì‘ë‹µ ìºì‹±.

ë™ì¼/ìœ ì‚¬ ì§ˆë¬¸ì— ëŒ€í•´ LLM í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
ì •ì  ì •ë³´(FAQ, ìš”ê¸ˆì œ ë“±)ì—ë§Œ ìºì‹œë¥¼ ì ìš©í•˜ê³ 
ë™ì  ì •ë³´(ì½”ë“œ êµ¬í˜„, ë””ë²„ê¹… ë“±)ëŠ” bypassí•©ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™: "ê°™ì€ ì§ˆë¬¸ì— ë‘ ë²ˆ ìƒê°í•˜ì§€ ë§ˆë¼."
"""

import re
import logging
import uuid
from typing import Optional

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CACHE_DB_DIR = "db_cache"
CACHE_COLLECTION = "response_cache"
DEFAULT_THRESHOLD = 0.95  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„ê³„ê°’

# ìºì‹± ë¶ˆê°€ íŒ¨í„´ (ë™ì /ì½”ë“œ ê´€ë ¨ ìš”ì²­)
NON_CACHEABLE_PATTERNS = [
    r"(ì½”ë“œ|code|êµ¬í˜„|implement|ì‘ì„±|write|debug|ë””ë²„ê¹…|fix|ìˆ˜ì •)",
    r"(íŒŒì¼|file|í”„ë¡œì íŠ¸|project).*\.(py|ts|js|yaml|json|md)",
    r"\[ESCALATE\]",
    r"(ë¦¬íŒ©í† ë§|refactor)",
    r"^/",  # CLI ëª…ë ¹ì–´
]


class SemanticCache:
    """ChromaDB ê¸°ë°˜ ì‹œë§¨í‹± ì‘ë‹µ ìºì‹œ.

    ìœ ì‚¬ë„ê°€ thresholdë¥¼ ë„˜ëŠ” ê³¼ê±° ì‘ë‹µì„ ì¦‰ì‹œ ë°˜í™˜í•˜ì—¬
    LLM í˜¸ì¶œì„ ì™„ì „íˆ ìƒëµí•©ë‹ˆë‹¤ (Short-Circuit).

    Attributes:
        threshold: ìºì‹œ íˆíŠ¸ë¡œ íŒì •í•  ìµœì†Œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ê¸°ë³¸ 0.95)
    """

    def __init__(
        self,
        db_dir: str = CACHE_DB_DIR,
        threshold: float = DEFAULT_THRESHOLD,
        encoder: Optional[SentenceTransformer] = None,
    ):
        self.threshold = threshold
        self._enabled = True

        try:
            self.client = chromadb.PersistentClient(path=db_dir)
            # ì¸ì½”ë”ëŠ” ì™¸ë¶€ ì£¼ì… ê°€ëŠ¥ (VectorMemoryì™€ ê³µìœ )
            self.encoder = encoder or SentenceTransformer("all-MiniLM-L6-v2")
            self.collection = self.client.get_or_create_collection(
                name=CACHE_COLLECTION,
                metadata={"hnsw:space": "cosine"},
            )
            logger.info(
                f"ğŸ’¾ Semantic Cache ì´ˆê¸°í™” ì™„ë£Œ "
                f"(threshold={self.threshold}, entries={self.collection.count()})"
            )
        except Exception as e:
            logger.error(f"âŒ Semantic Cache ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._enabled = False
            self.collection = None

    def get(self, query: str) -> Optional[str]:
        """ìºì‹œì—ì„œ ìœ ì‚¬í•œ ì¿¼ë¦¬ì˜ ì‘ë‹µì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬

        Returns:
            ìœ ì‚¬ë„ thresholdë¥¼ ë„˜ëŠ” ìºì‹œëœ ì‘ë‹µ, ì—†ìœ¼ë©´ None
        """
        if not self._enabled or not self.collection:
            return None

        if not self._is_cacheable(query):
            logger.debug("ğŸ”„ Cache bypass: ë™ì  ìš”ì²­ ê°ì§€")
            return None

        try:
            embedding = self.encoder.encode(query).tolist()
            results = self.collection.query(
                query_embeddings=[embedding],
                n_results=1,
            )

            if not results["ids"] or not results["ids"][0]:
                return None

            # ChromaDBëŠ” cosine distanceë¥¼ ë°˜í™˜ (0 = ë™ì¼, 2 = ì™„ì „ ë°˜ëŒ€)
            # ìœ ì‚¬ë„ = 1 - distance
            distance = results["distances"][0][0]
            similarity = 1 - distance

            if similarity >= self.threshold:
                cached_response = results["documents"][0][0]
                logger.info(
                    f"âœ¨ Cache HIT! (ìœ ì‚¬ë„: {similarity:.4f} â‰¥ {self.threshold})"
                )
                return cached_response

            logger.debug(
                f"ğŸ”„ Cache MISS (ìœ ì‚¬ë„: {similarity:.4f} < {self.threshold})"
            )
            return None

        except Exception as e:
            logger.error(f"âŒ Cache ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def put(self, query: str, response: str) -> None:
        """ì¿¼ë¦¬-ì‘ë‹µ ìŒì„ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            query: ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬
            response: LLMì´ ìƒì„±í•œ ì‘ë‹µ
        """
        if not self._enabled or not self.collection:
            return

        if not self._is_cacheable(query):
            return

        try:
            embedding = self.encoder.encode(query).tolist()
            doc_id = str(uuid.uuid4())

            self.collection.add(
                documents=[response],
                embeddings=[embedding],
                metadatas=[{"query": query[:500]}],
                ids=[doc_id],
            )
            logger.debug(f"ğŸ’¾ Cache stored: {doc_id}")

        except Exception as e:
            logger.error(f"âŒ Cache ì €ì¥ ì‹¤íŒ¨: {e}")

    def _is_cacheable(self, query: str) -> bool:
        """ì¿¼ë¦¬ê°€ ìºì‹± ê°€ëŠ¥í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.

        ì½”ë“œ êµ¬í˜„, ë””ë²„ê¹… ë“± ë™ì  ìš”ì²­ì€ ìºì‹±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        for pattern in NON_CACHEABLE_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE):
                return False
        return True

    def count(self) -> int:
        """ìºì‹œëœ í•­ëª© ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.collection:
            return self.collection.count()
        return 0

    def clear(self) -> None:
        """ìºì‹œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if self._enabled and self.client:
            self.client.delete_collection(CACHE_COLLECTION)
            self.collection = self.client.get_or_create_collection(
                name=CACHE_COLLECTION,
                metadata={"hnsw:space": "cosine"},
            )
            logger.info("ğŸ—‘ï¸ Semantic Cache ì´ˆê¸°í™” ì™„ë£Œ")
