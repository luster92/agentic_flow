"""
History Manager (SQLite)
========================
ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ëª¨ë“ˆ:
- SQLite ê¸°ë°˜ ì˜ì†í™” (ë°ì´í„° ë¬´ê²°ì„± ë° ê²€ìƒ‰ ì„±ëŠ¥ í™•ë³´)
- í”„ë¡œì íŠ¸ë³„ ë ˆì½”ë“œ ê´€ë¦¬ (projects í…Œì´ë¸”)
- ë©”ì‹œì§€ ì´ë ¥ ê´€ë¦¬ (messages í…Œì´ë¸”)
- ê¸°ì¡´ JSONL íŒŒì¼ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì›
"""

import json
import os
import glob
import logging
import sqlite3
from datetime import datetime, timezone
from dataclasses import dataclass

logger = logging.getLogger(__name__)

DEFAULT_HISTORY_DIR = "history"
DEFAULT_CONTEXT_WINDOW = 20
DB_FILENAME = "agentic_flow.db"


class HistoryManager:
    """
    SQLite ê¸°ë°˜ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ì.
    """

    def __init__(
        self,
        project_name: str = "default",
        base_dir: str = DEFAULT_HISTORY_DIR,
        context_window: int = DEFAULT_CONTEXT_WINDOW,
    ):
        self.project_name = project_name
        self.base_dir = base_dir
        self.context_window = context_window
        self.db_path = os.path.join(self.base_dir, DB_FILENAME)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        if not os.path.exists(self.base_dir):
            os.makedirs(self.base_dir)

        # DB ì´ˆê¸°í™” ë° í”„ë¡œì íŠ¸ ID ë¡œë“œ
        self._init_db()
        self.project_id = self._get_or_create_project_id()
        
        # ë ˆê±°ì‹œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
        self._check_legacy_migration()

    def _init_db(self) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”."""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS projects (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT UNIQUE NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    metadata TEXT  -- JSON string
                )
            """)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    project_id INTEGER NOT NULL,
                    role TEXT NOT NULL,
                    content TEXT NOT NULL,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    metadata TEXT, -- JSON string
                    FOREIGN KEY(project_id) REFERENCES projects(id)
                )
            """)
            # ì¸ë±ìŠ¤ ì¶”ê°€ (ì¡°íšŒ ì„±ëŠ¥ ìµœì í™”)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_project_id ON messages(project_id)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_timestamp ON messages(timestamp)")

    def _get_or_create_project_id(self) -> int:
        """í”„ë¡œì íŠ¸ ì´ë¦„ì„ IDë¡œ ë³€í™˜ (ì—†ìœ¼ë©´ ìƒì„±)."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("SELECT id FROM projects WHERE name = ?", (self.project_name,))
            row = cursor.fetchone()
            if row:
                return row[0]
            
            # ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
            cursor = conn.execute(
                "INSERT INTO projects (name, metadata) VALUES (?, ?)",
                (self.project_name, "{}")
            )
            return cursor.lastrowid

    def add_message(self, role: str, content: str, metadata: dict | None = None) -> None:
        """ë©”ì‹œì§€ ì¶”ê°€."""
        ts = datetime.now(timezone.utc).isoformat()
        meta_json = json.dumps(metadata, ensure_ascii=False) if metadata else None
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT INTO messages (project_id, role, content, timestamp, metadata)
                VALUES (?, ?, ?, ?, ?)
                """,
                (self.project_id, role, content, ts, meta_json)
            )
        logger.debug(f"ğŸ“ ë©”ì‹œì§€ DB ì €ì¥ ({self.project_name}): {role}")

    def get_context(self, window_size: int | None = None) -> list[dict]:
        """ìµœê·¼ ë©”ì‹œì§€ ì¡°íšŒ (ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ìš©)."""
        limit = window_size or self.context_window
        
        with sqlite3.connect(self.db_path) as conn:
            # ìµœê·¼ Nê°œë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì •ë ¬ í›„ ì„œë¸Œì¿¼ë¦¬ í™œìš© ê°€ëŠ¥í•˜ì§€ë§Œ,
            # í¸ì˜ìƒ ì—­ìˆœ ì¡°íšŒ í›„ Pythonì—ì„œ ë’¤ì§‘ëŠ”ë‹¤.
            cursor = conn.execute(
                """
                SELECT role, content 
                FROM messages 
                WHERE project_id = ? AND role IN ('user', 'assistant', 'system')
                ORDER BY id DESC LIMIT ?
                """,
                (self.project_id, limit)
            )
            rows = cursor.fetchall()
        
        # ìµœì‹ ìˆœ(DESC) ê²°ê³¼ë¥¼ ì‹œê°„ìˆœ(ASC)ìœ¼ë¡œ ë’¤ì§‘ê¸°
        return [{"role": r[0], "content": r[1]} for r in reversed(rows)]

    def get_full_history(self) -> list[dict]:
        """ì „ì²´ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ (ë©”íƒ€ë°ì´í„° í¬í•¨)."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """
                SELECT role, content, timestamp, metadata 
                FROM messages 
                WHERE project_id = ? 
                ORDER BY id ASC
                """,
                (self.project_id,)
            )
            rows = cursor.fetchall()
            
        result = []
        for r in rows:
            meta = json.loads(r[3]) if r[3] else None
            result.append({
                "role": r[0],
                "content": r[1],
                "timestamp": r[2],
                "metadata": meta
            })
        return result

    def clear(self) -> None:
        """í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ë©”ì‹œì§€ ê¸°ë¡ ì‚­ì œ (ì´ˆê¸°í™”)."""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("DELETE FROM messages WHERE project_id = ?", (self.project_id,))
        logger.info(f"ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”ë¨ ({self.project_name})")

    def get_stats(self) -> dict:
        """í†µê³„ ì •ë³´ ì¡°íšŒ."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT role, COUNT(*) FROM messages WHERE project_id = ? GROUP BY role",
                (self.project_id,)
            )
            by_role = dict(cursor.fetchall())
            
            total = sum(by_role.values())
        
        return {
            "project": self.project_name,
            "total_messages": total,
            "by_role": by_role,
            "file_path": self.db_path,
        }

    @staticmethod
    def list_projects(base_dir: str = DEFAULT_HISTORY_DIR) -> list[str]:
        """DBì— ì €ì¥ëœ í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ."""
        db_path = os.path.join(base_dir, DB_FILENAME)
        if not os.path.exists(db_path):
            return []
            
        try:
            with sqlite3.connect(db_path) as conn:
                cursor = conn.execute("SELECT name FROM projects ORDER BY name")
                return [row[0] for row in cursor.fetchall()]
        except sqlite3.Error:
            return []

    # â”€â”€ Legacy Migration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _check_legacy_migration(self) -> None:
        """
        ë™ì¼í•œ ì´ë¦„ì˜ .jsonl íŒŒì¼ì´ ìˆê³  DBê°€ ë¹„ì–´ìˆë‹¤ë©´ ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰.
        """
        jsonl_path = os.path.join(self.base_dir, f"{self.project_name}.jsonl")
        if not os.path.exists(jsonl_path):
            return
            
        # DBì— ë©”ì‹œì§€ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        if self.get_stats()["total_messages"] > 0:
            return

        logger.info(f"ğŸ”„ JSONL ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘: {jsonl_path} â†’ SQLite")
        try:
            with open(jsonl_path, "r", encoding="utf-8") as f:
                lines = f.readlines()
                
            with sqlite3.connect(self.db_path) as conn:
                for line in lines:
                    if not line.strip():
                        continue
                    data = json.loads(line)
                    meta_str = json.dumps(data.get("metadata", {}), ensure_ascii=False)
                    conn.execute(
                        """
                        INSERT INTO messages (project_id, role, content, timestamp, metadata)
                        VALUES (?, ?, ?, ?, ?)
                        """,
                        (self.project_id, data["role"], data["content"], data.get("timestamp"), meta_str)
                    )
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì›ë³¸ íŒŒì¼ ë°±ì—… (ì´ë¦„ ë³€ê²½)
            os.rename(jsonl_path, jsonl_path + ".bak")
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ (ì›ë³¸ .bak ì²˜ë¦¬ë¨)")
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")

    # â”€â”€ Semantic Context Filtering & Compression â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def compress_old_memories(
        self,
        threshold_msgs: int = 40,
        compress_count: int = 20,
        base_url: str = "http://localhost:4000"
    ) -> bool:
        """
        ì˜¤ë˜ëœ ë©”ì‹œì§€ê°€ íŠ¹ì • ê°œìˆ˜(threshold_msgs)ë¥¼ ì´ˆê³¼í•˜ë©´, ê°€ì¥ ì˜¤ë˜ëœ Nê°œ(compress_count)ë¥¼
        Dense English (ì˜ë¯¸ë¡ ì  ì¶•ì•½ ì–¸ì–´)ë¡œ ì••ì¶•í•˜ì—¬ ë‹¨ì¼ ë¸”ë¡ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT COUNT(*) FROM messages WHERE project_id = ?",
                (self.project_id,)
            )
            total = cursor.fetchone()[0]
            
        if total <= threshold_msgs:
            return False
            
        with sqlite3.connect(self.db_path) as conn:
            # ë³´ì¡´í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ìµœìƒë‹¨) ë“±ì€ ì •ì±…ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜,
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì‹œê°„ìˆœìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ ì¼ë°˜ ëŒ€í™”/ë„êµ¬ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            cursor = conn.execute(
                "SELECT id, role, content, timestamp FROM messages WHERE project_id = ? ORDER BY id ASC LIMIT ?",
                (self.project_id, compress_count)
            )
            rows = cursor.fetchall()
            
        if not rows:
            return False
            
        # 1. í…ìŠ¤íŠ¸ ì§ë ¬í™”
        text_to_compress = []
        for r in rows:
            text_to_compress.append(f"[{r[1]}] {r[2]}")
        conversation_text = "\\n".join(text_to_compress)
        
        # 2. LLM í˜¸ì¶œ (ë¡œì»¬ ê²½ëŸ‰ ëª¨ë¸)
        from openai import AsyncOpenAI
        client = AsyncOpenAI(base_url=base_url, api_key="not-needed")
        
        system_prompt = (
            "You are a semantic memory compressor. "
            "Compress the following conversation log into extremely dense English shorthand. "
            "Focus only on facts, decisions, context, and constraints. "
            "Omit all conversational filler, grammar, and polite words. "
            "Use dense formats like 'req:auth|db:ok|err:timeout'. Do NOT use full sentences. "
            "Maximize token efficiency while preserving factual integrity."
        )
        
        try:
            response = await client.chat.completions.create(
                model="local-helper",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation_text},
                ],
                temperature=0.1,
                max_tokens=1024,
            )
            compressed_result = response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì••ì¶• ì‹¤íŒ¨: {e}")
            return False
            
        if not compressed_result:
            return False
            
        final_content = f"[COMPRESSED_MEMORY]\\n{compressed_result}"
        # ê°€ì¥ ìµœê·¼ ì••ì¶• ë©”ì‹œì§€ì˜ timestampë¥¼ ì‚¬ìš©í•´ ì •ë ¬ ìœ ì§€
        last_timestamp = rows[-1][3]
        ids_to_delete = [r[0] for r in rows]
        
        # 3. DB êµì²´ íŠ¸ëœì­ì…˜ (ì›ë˜ ìˆœì„œë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì²« ë²ˆì§¸ í–‰ì„ ì¬í™œìš©)
        with sqlite3.connect(self.db_path) as conn:
            keep_id = ids_to_delete[0]
            delete_ids = ids_to_delete[1:]
            
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¥¼ ì••ì¶• ë¸”ë¡ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            conn.execute(
                "UPDATE messages SET role = ?, content = ?, timestamp = ?, metadata = ? WHERE id = ?",
                ("system", final_content, last_timestamp, None, keep_id)
            )
            
            # ë‚˜ë¨¸ì§€ ë³‘í•©ëœ ë©”ì‹œì§€ ì‚­ì œ
            if delete_ids:
                placeholders = ",".join(["?"] * len(delete_ids))
                conn.execute(
                    f"DELETE FROM messages WHERE id IN ({placeholders})",
                    delete_ids
                )
            
        logger.info(f"ğŸ—œï¸ ê³¼ê±° ë©”ì‹œì§€ {len(ids_to_delete)}ê°œë¥¼ 1ê°œì˜ ì˜ë¯¸ë¡ ì  ì••ì¶•(Dense) ë¸”ë¡ìœ¼ë¡œ ì¹˜í™˜í–ˆìŠµë‹ˆë‹¤.")
        return True

    def get_summarized_context(self, max_recent: int = 3) -> dict:
        """í•¸ë“œì˜¤í”„ìš© ìš”ì•½ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        ì „ì²´ ëŒ€í™” ë¡œê·¸ ëŒ€ì‹  í•µì‹¬ ì •ë³´ë§Œ ì¶”ë ¤ì„œ ë°˜í™˜í•¨ìœ¼ë¡œì¨
        ì»¨í…ìŠ¤íŠ¸ ì˜¤ì—¼ì„ ë°©ì§€í•˜ê³  í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.

        Args:
            max_recent: ìµœê·¼ ë©”ì‹œì§€ í¬í•¨ ê°œìˆ˜

        Returns:
            dict: {
                "summary": str,        # ëŒ€í™” í•µì‹¬ ìš”ì•½
                "entities": dict,      # ì¶”ì¶œëœ í•µì‹¬ ë°ì´í„°
                "recent_messages": list # ìµœê·¼ Ní„´ ë©”ì‹œì§€
            }
        """
        full = self.get_full_history()

        # ìµœê·¼ ë©”ì‹œì§€ ì¶”ì¶œ
        recent = full[-max_recent:] if full else []
        recent_msgs = [{"role": m["role"], "content": m["content"]} for m in recent]

        # í•µì‹¬ ì •ë³´ ì¶”ì¶œ: routing ë° handler ë©”íƒ€ë°ì´í„°ì—ì„œ ì—”í‹°í‹° ìˆ˜ì§‘
        entities: dict[str, str] = {}
        key_points: list[str] = []

        for msg in full:
            meta = msg.get("metadata") or {}

            # ë¼ìš°íŒ… ê²°ì • ê¸°ë¡
            if meta.get("type") == "routing":
                key_points.append(f"[Routing] {msg['content']}")

            # í•¸ë“¤ëŸ¬ ì •ë³´
            handler = meta.get("handler", "")
            if handler:
                entities["last_handler"] = handler

            # ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì‚¬ìœ 
            esc_reason = meta.get("reason", "")
            if esc_reason and meta.get("handler"):
                entities["escalation_reason"] = esc_reason

        # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì²« ìš”ì²­ê³¼ ë§ˆì§€ë§‰ ìš”ì²­ ìš”ì•½
        user_msgs = [m for m in full if m["role"] == "user"]
        if user_msgs:
            entities["first_request"] = user_msgs[0]["content"][:200]
            if len(user_msgs) > 1:
                entities["latest_request"] = user_msgs[-1]["content"][:200]

        # ìš”ì•½ ë¬¸ìì—´ ìƒì„±
        summary_parts = []
        if entities.get("first_request"):
            summary_parts.append(f"ì´ˆê¸° ìš”ì²­: {entities['first_request'][:100]}")
        if key_points:
            summary_parts.append(f"ë¼ìš°íŒ… ì´ë ¥: {len(key_points)}ê±´")
        summary_parts.append(f"ì´ {len(full)}í„´ ëŒ€í™” ì§„í–‰")

        return {
            "summary": " | ".join(summary_parts),
            "entities": entities,
            "recent_messages": recent_msgs,
        }

    # â”€â”€ Metadata Methods â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def set_metadata(self, **kwargs) -> None:
        """í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸."""
        current = self.get_metadata()
        current.update(kwargs)
        json_str = json.dumps(current, ensure_ascii=False)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                "UPDATE projects SET metadata = ? WHERE id = ?",
                (json_str, self.project_id)
            )

    def get_metadata(self) -> dict:
        """í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("SELECT metadata FROM projects WHERE id = ?", (self.project_id,))
            row = cursor.fetchone()
            if row and row[0]:
                return json.loads(row[0])
            return {}
