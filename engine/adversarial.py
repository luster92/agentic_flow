"""
Adversarial Verification Engine â€” ì•…ë§ˆì˜ ë³€í˜¸ì¸ í† ë¡  ë£¨í”„
========================================================
ë³€ì¦ë²•ì  ì •-ë°˜-í•©(Thesis-Antithesis-Synthesis) êµ¬ì¡°ë¥¼ í†µí•´
ë‹¨ì¼ ì—ì´ì „íŠ¸ì˜ í™˜ê°ê³¼ í¸í–¥ì„ ê·¹ë³µí•©ë‹ˆë‹¤.

í† ë¡  í† í´ë¡œì§€:
  Round 0: Worker â†’ ì´ˆì•ˆ ìƒì„±
  Round N (ê³µê²©): Devil's Advocate â†’ ê³µê²© ë¦¬ìŠ¤íŠ¸ ìƒì„±
  Round N (íŒê²°): Moderator â†’ ìœ íš¨ì„± ì ìˆ˜ í‰ê°€
  Round N (ìˆ˜ì •): Worker â†’ ë¹„íŒ ë°˜ì˜ ìˆ˜ì •

ì•ˆì „ì¥ì¹˜:
  - max_rounds ì´ˆê³¼ ì‹œ ê°•ì œ ì¢…ë£Œ
  - Moderator ESCALATE íŒê²° ì‹œ HITL íŠ¸ë¦¬ê±°
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field
from typing import Any

from openai import AsyncOpenAI

from engine.persona import PersonaManager

logger = logging.getLogger(__name__)


@dataclass
class DebateRound:
    """í† ë¡  ë¼ìš´ë“œ ê¸°ë¡."""
    round_number: int
    critique: str = ""           # Devil's Advocateì˜ ê³µê²©
    critique_parsed: dict[str, Any] = field(default_factory=dict)
    judgment: str = ""           # Moderatorì˜ íŒê²°
    judgment_parsed: dict[str, Any] = field(default_factory=dict)
    revision: str = ""           # Workerì˜ ìˆ˜ì •ì•ˆ
    validity_score: float = 10.0


@dataclass
class DebateResult:
    """í† ë¡  ìµœì¢… ê²°ê³¼."""
    final_proposal: str          # ìµœì¢… ìŠ¹ì¸ëœ ì•ˆ
    approved: bool               # ìŠ¹ì¸ ì—¬ë¶€
    total_rounds: int            # ì§„í–‰ëœ ë¼ìš´ë“œ ìˆ˜
    rounds: list[DebateRound] = field(default_factory=list)
    escalated: bool = False      # HITL ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì—¬ë¶€
    report: str = ""             # ê²€ì¦ ë¦¬í¬íŠ¸


class DebateLoop:
    """ë³€ì¦ë²•ì  í† ë¡  ë£¨í”„ ì»¨íŠ¸ë¡¤ëŸ¬.

    Workerì˜ ì œì•ˆì„ Devil's Advocateê°€ ê³µê²©í•˜ê³ ,
    Moderatorê°€ íŒê²°í•˜ë©°, í•©ì˜ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ìˆœí™˜í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        persona_manager: PersonaManager,
        base_url: str = "http://localhost:4000",
        model: str = "local-worker",
    ) -> None:
        self._persona = persona_manager
        self._client = AsyncOpenAI(base_url=base_url, api_key="not-needed")
        self._model = model

    async def run(
        self,
        proposal: str,
        task: str,
        max_rounds: int = 3,
        approval_threshold: float = 7.0,
    ) -> DebateResult:
        """ì ëŒ€ì  ê²€ì¦ í† ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            proposal: Workerì˜ ì´ˆì•ˆ
            task: ì›ë³¸ ì‚¬ìš©ì ìš”ì²­
            max_rounds: ìµœëŒ€ ë¼ìš´ë“œ ìˆ˜
            approval_threshold: ìŠ¹ì¸ ì„ê³„ê°’ (ì´ ê°’ ë¯¸ë§Œì´ë©´ ìŠ¹ì¸)

        Returns:
            DebateResult: ìµœì¢… ê²€ì¦ ê²°ê³¼
        """
        rounds: list[DebateRound] = []
        current_proposal = proposal
        original_persona_id = self._persona.current_id

        logger.info(
            f"âš”ï¸ Debate started: max_rounds={max_rounds}, "
            f"threshold={approval_threshold}"
        )

        try:
            for round_num in range(1, max_rounds + 1):
                logger.info(f"âš”ï¸ â”€â”€ Round {round_num}/{max_rounds} â”€â”€")
                debate_round = DebateRound(round_number=round_num)

                # â”€â”€ Step A: ê³µê²© (Devil's Advocate) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                critique = await self._attack(current_proposal, task)
                debate_round.critique = critique
                debate_round.critique_parsed = self._parse_json_safe(critique)

                # â”€â”€ Step B: íŒê²° (Moderator) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                judgment = await self._judge(
                    current_proposal, critique, task
                )
                debate_round.judgment = judgment
                debate_round.judgment_parsed = self._parse_json_safe(judgment)

                # ìœ íš¨ì„± ì ìˆ˜ ì¶”ì¶œ
                validity_score = debate_round.judgment_parsed.get(
                    "validity_score", 10.0
                )
                try:
                    validity_score = float(validity_score)
                except (TypeError, ValueError):
                    validity_score = 10.0
                debate_round.validity_score = validity_score

                verdict = debate_round.judgment_parsed.get(
                    "verdict", "REVISE"
                ).upper()

                logger.info(
                    f"âš”ï¸ Round {round_num} score: {validity_score}/10 "
                    f"| verdict: {verdict}"
                )

                rounds.append(debate_round)

                # â”€â”€ íŒê²° ë¶„ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if verdict == "ESCALATE":
                    logger.warning(
                        "ğŸš¨ Moderator requested ESCALATE â†’ HITL trigger"
                    )
                    return DebateResult(
                        final_proposal=current_proposal,
                        approved=False,
                        total_rounds=round_num,
                        rounds=rounds,
                        escalated=True,
                        report=self._generate_report(rounds),
                    )

                if validity_score < approval_threshold or verdict == "APPROVE":
                    logger.info(
                        f"âœ… Debate resolved at round {round_num} "
                        f"(score {validity_score} < {approval_threshold})"
                    )
                    return DebateResult(
                        final_proposal=current_proposal,
                        approved=True,
                        total_rounds=round_num,
                        rounds=rounds,
                        report=self._generate_report(rounds),
                    )

                # â”€â”€ Step C: ìˆ˜ì • (Worker) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if round_num < max_rounds:
                    revision = await self._revise(
                        current_proposal, critique, judgment, task
                    )
                    debate_round.revision = revision
                    current_proposal = revision

            # â”€â”€ max_rounds ë„ë‹¬: ê°•ì œ ìŠ¹ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.warning(
                f"âš ï¸ Max rounds ({max_rounds}) reached. "
                "Forcing approval with last revision."
            )
            return DebateResult(
                final_proposal=current_proposal,
                approved=True,
                total_rounds=max_rounds,
                rounds=rounds,
                report=self._generate_report(rounds),
            )

        finally:
            # ì›ë˜ í˜ë¥´ì†Œë‚˜ë¡œ ë³µê·€
            if self._persona.current_id != original_persona_id:
                try:
                    self._persona.switch_persona(
                        original_persona_id,
                        reason="Debate loop completed, restoring original",
                    )
                except FileNotFoundError:
                    pass

    async def _attack(self, proposal: str, task: str) -> str:
        """Devil's Advocate í˜ë¥´ì†Œë‚˜ë¡œ ê³µê²©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        self._persona.switch_persona("devil", reason="Debate: attack phase")
        transition_msg = self._persona.get_transition_message()

        messages = [
            {"role": "system", "content": self._persona.get_system_prompt()},
            {"role": "system", "content": transition_msg},
            {
                "role": "user",
                "content": (
                    f"## ì›ë³¸ ìš”ì²­\n{task}\n\n"
                    f"## ì‘ì—…ìì˜ ì œì•ˆ\n{proposal}\n\n"
                    "ìœ„ ì œì•ˆì„ ë¶„ì„í•˜ì—¬ ê³µê²© ë¦¬ìŠ¤íŠ¸(Attack Vector)ë¥¼ ìƒì„±í•´ë¼."
                ),
            },
        ]

        try:
            response = await self._client.chat.completions.create(
                model=self._model,
                messages=messages,
                temperature=self._persona.get_temperature(),
                max_tokens=2048,
            )
            result = response.choices[0].message.content or ""
            logger.info(f"ğŸ˜ˆ Devil's Advocate attack generated ({len(result)} chars)")
            return result
        except Exception as e:
            logger.error(f"âŒ Devil's Advocate attack failed: {e}")
            return json.dumps({
                "attack_vectors": [],
                "overall_assessment": f"Attack generation failed: {e}",
                "recommendation": "CONDITIONAL_PASS",
            })

    async def _judge(
        self, proposal: str, critique: str, task: str
    ) -> str:
        """Moderator í˜ë¥´ì†Œë‚˜ë¡œ íŒê²°ì„ ë‚´ë¦½ë‹ˆë‹¤."""
        self._persona.switch_persona(
            "moderator", reason="Debate: judgment phase"
        )
        transition_msg = self._persona.get_transition_message()

        messages = [
            {"role": "system", "content": self._persona.get_system_prompt()},
            {"role": "system", "content": transition_msg},
            {
                "role": "user",
                "content": (
                    f"## ì›ë³¸ ìš”ì²­\n{task}\n\n"
                    f"## ì‘ì—…ìì˜ ì œì•ˆ\n{proposal}\n\n"
                    f"## ë¹„íŒìì˜ ê³µê²©\n{critique}\n\n"
                    "ìœ„ ê³µê²©ì˜ ìœ íš¨ì„±ì„ í‰ê°€í•˜ê³  íŒê²°ì„ ë‚´ë ¤ë¼."
                ),
            },
        ]

        try:
            response = await self._client.chat.completions.create(
                model=self._model,
                messages=messages,
                temperature=self._persona.get_temperature(),
                max_tokens=1024,
            )
            result = response.choices[0].message.content or ""
            logger.info(f"âš–ï¸ Moderator judgment rendered ({len(result)} chars)")
            return result
        except Exception as e:
            logger.error(f"âŒ Moderator judgment failed: {e}")
            return json.dumps({
                "validity_score": 0,
                "verdict": "APPROVE",
                "reasoning": f"Judgment failed: {e}",
            })

    async def _revise(
        self,
        proposal: str,
        critique: str,
        judgment: str,
        task: str,
    ) -> str:
        """Worker í˜ë¥´ì†Œë‚˜ë¡œ ì œì•ˆì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
        self._persona.switch_persona("worker", reason="Debate: revision phase")
        transition_msg = self._persona.get_transition_message()

        messages = [
            {"role": "system", "content": self._persona.get_system_prompt()},
            {"role": "system", "content": transition_msg},
            {
                "role": "user",
                "content": (
                    f"## ì›ë³¸ ìš”ì²­\n{task}\n\n"
                    f"## ë„¤ê°€ ì‘ì„±í•œ ì´ì „ ì œì•ˆ\n{proposal}\n\n"
                    f"## ë¹„íŒìì˜ ê³µê²©\n{critique}\n\n"
                    f"## ì¤‘ì¬ìì˜ íŒê²°\n{judgment}\n\n"
                    "ë¹„íŒ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ì œì•ˆì„ ìˆ˜ì •í•´ë¼. "
                    "ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ ìˆ˜ì •ëœ ì „ì²´ ê²°ê³¼ë¬¼ë§Œ ì¶œë ¥í•´ë¼."
                ),
            },
        ]

        try:
            response = await self._client.chat.completions.create(
                model=self._model,
                messages=messages,
                temperature=self._persona.get_temperature(),
                max_tokens=4096,
            )
            result = response.choices[0].message.content or proposal
            logger.info(f"âœï¸ Worker revision completed ({len(result)} chars)")
            return result
        except Exception as e:
            logger.error(f"âŒ Worker revision failed: {e}")
            return proposal  # ìˆ˜ì • ì‹¤íŒ¨ ì‹œ ì›ì•ˆ ìœ ì§€

    @staticmethod
    def _parse_json_safe(text: str) -> dict[str, Any]:
        """JSON íŒŒì‹± ì‹œë„, ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¥¼ ë˜í•‘í•˜ì—¬ ë°˜í™˜."""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•íƒœ)
            import re
            json_match = re.search(r"```(?:json)?\s*\n(.*?)```", text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            return json.loads(text)
        except (json.JSONDecodeError, TypeError):
            return {"raw_text": text}

    @staticmethod
    def _generate_report(rounds: list[DebateRound]) -> str:
        """ê²€ì¦ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        lines = [
            "# ì ëŒ€ì  ê²€ì¦ ë¦¬í¬íŠ¸ (Adversarial Verification Report)",
            f"ì´ ë¼ìš´ë“œ: {len(rounds)}",
            "",
        ]

        for r in rounds:
            lines.append(f"## Round {r.round_number}")
            lines.append(f"ìœ íš¨ì„± ì ìˆ˜: {r.validity_score}/10")

            verdict = r.judgment_parsed.get("verdict", "N/A")
            lines.append(f"íŒê²°: {verdict}")

            attacks = r.critique_parsed.get("attack_vectors", [])
            if attacks:
                lines.append(f"ê³µê²© ë²¡í„° ìˆ˜: {len(attacks)}")
                for a in attacks[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    if isinstance(a, dict):
                        lines.append(
                            f"  - [{a.get('severity', '?')}] "
                            f"{a.get('finding', 'N/A')}"
                        )

            lines.append("")

        return "\n".join(lines)
